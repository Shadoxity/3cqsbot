{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shadoxity/3cqsbot/blob/main/fooocus_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d128e8-f996-40c7-bfbf-371ba402bbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.17.0\n",
            "    Uninstalling pygit2-1.17.0:\n",
            "      Successfully uninstalled pygit2-1.17.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6725 (delta 2), reused 0 (delta 0), pack-reused 6721 (from 3)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.27 MiB | 15.44 MiB/s, done.\n",
            "Resolving deltas: 100% (3876/3876), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 45.5MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 45.4MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 47.6MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 245MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:35<00:00, 203MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 252MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://a59747d92ac4a5216b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "2025-02-13 20:47:09.107464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739479629.325457    1345 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739479629.381784    1345 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-13 20:47:09.839301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 341\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://a59747d92ac4a5216b.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8438492130669456053\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Cute and petite redhead, blue eyes with LFB in green sexy lingerie playfully looking at the camera, nipples through top, large D breasts, very detailed, beautiful, delicate, intricate, elegant, highly enhanced, wonderful, cute, divine holy, dramatic cinematic light, sharp focus, epic scenic, ambient, artistic, thought, clear, crisp, accepted\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Cute and petite redhead, blue eyes with LFB in green sexy lingerie playfully looking at the camera, nipples through top, large D breasts, satisfying sweet exquisite detail, perfect light, directed focus, extremely detailed, intricate, innocent, stunning, mystical, creative, cute, elegant, sharp background bright colors, highly saturated, dramatic cinematic, rich deep color\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.81 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.88 seconds\n",
            "100% 30/30 [00:24<00:00,  1.23it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-02-13/log.html\n",
            "Generating and saving time: 29.17 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "100% 30/30 [00:23<00:00,  1.26it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-02-13/log.html\n",
            "Generating and saving time: 27.32 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 56.49 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 59.35 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8687515035346557368\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Make her topless, beautiful detailed perfect pretty shining holy great magnificent elegant full polished sharp focus, dazzling light, attractive glowing shiny deep colors, extremely complex, very inspirational, thought worthy, splendid, brilliant, colorful, dramatic scenic breathtaking background, marvelous composition, professional color, intricate, highly dynamic, atmosphere, rich vivid, wonderful, epic, cinematic, artistic, fine detail\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Make her topless, beautiful detailed perfect cute pretty marvelous elegant pure, flowing intricate stunning, noble, sublime, magic, intense, dramatic, sharp focus, epic, brilliant, highly detail, extremely professional, cinematic, artistic, innocent, mystical light, clear background, inspired, designed, vivid, lovely, amazing, symmetry, ambient, vibrant, illuminated, peaceful, shiny\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.08 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.68 seconds\n",
            " 73% 22/30 [00:17<00:06,  1.23it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 19.61 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 21.72 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.89 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1141363303392345246\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/clip_vision_vit_h.safetensors\" to /content/Fooocus/models/clip_vision/clip_vision_vit_h.safetensors\n",
            "\n",
            "100% 1.84G/1.84G [00:17<00:00, 116MB/s] \n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_ip_negative.safetensors\" to /content/Fooocus/models/controlnet/fooocus_ip_negative.safetensors\n",
            "\n",
            "100% 64.1k/64.1k [00:00<00:00, 19.7MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus-face_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus-face_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:06<00:00, 161MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Topless lusty red head with blue eyes, exquisite detail, extremely detailed, glowing, mystical, radiant light, beautiful, intricate, elegant, highly coherent, colorful, complex, surreal, artistic, sharp focus, fine composition, great modern contemporary cinematic set, professional, winning, perfect,,,, healthy, vibrant, unique, best, novel, romantic, exciting\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Topless lusty red head with blue eyes, highly detailed, sublime, extremely beautiful, aesthetic, lush background, intricate, elegant, divine, magical, sharp focus, luxurious, dramatic cinematic, attractive, thought, best, romantic, perfect, pretty, full color, epic composition, amazing, great classic, fine, artistic, brilliant, creative, awesome, winning, fabulous\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/Fooocus/models/controlnet/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 302MB/s] \n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/Fooocus/models/controlnet/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 316MB/s]\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.51 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.66 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 42.88 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "100% 30/30 [00:23<00:00,  1.26it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-02-13/log.html\n",
            "Generating and saving time: 27.64 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "100% 30/30 [00:24<00:00,  1.23it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-02-13/log.html\n",
            "Generating and saving time: 27.75 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 55.39 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 98.33 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2199, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/Fooocus/launch.py\", line 152, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/Fooocus/webui.py\", line 1120, in <module>\n",
            "    shared.gradio_root.launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2115, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2203, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/networking.py\", line 49, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7865 <> https://a59747d92ac4a5216b.gradio.live\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!wget -O 'models/checkpoint/lustify_sdxl_nsfw.safetensors' \"https://civitai.com/api/download/models/1094291?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download additional Lora's and Checkpoints\n",
        "!mkdir -p /content/Fooocus/models/checkpoints\n",
        "!mkdir -p /content/Fooocus/models/loras\n",
        "\n",
        "#Checkpoints (Template) !wget -O /content/Fooocus/models/checkpoints/MODEL_NAME.safetensors MODEL_URL`\n",
        "!wget -O /content/Fooocus/models/checkpoints/lustify_sdxl_nsfw.safetensors \"https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/4138/lustifyEndgame.OH7I.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22lustifySDXLNSFW_endgame.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250213/us-east-1/s3/aws4_request&X-Amz-Date=20250213T210415Z&X-Amz-SignedHeaders=host&X-Amz-Signature=352dd3c9ceed59f79887a0ae7d76acb986e555fa233f6c26ba6ad67e16c2a222\"\n",
        "\n",
        "#Loras (template) !wget -O /content/Fooocus/models/loras/MODEL_NAME.safetensors MODEL_URL`\n",
        "!wget -O /content/Fooocus/models/loras/large_flat_breasts_SDXL.safetensors \"https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/3326444/largeFlatBreastsSDXL.kI8b.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22large_flat_breasts_SDXL.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250213/us-east-1/s3/aws4_request&X-Amz-Date=20250213T203048Z&X-Amz-SignedHeaders=host&X-Amz-Signature=5a64f1299154fa5ea285b2a091c022a40e2e21c06d15e07e8a4b1d06bb7998bf\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ILfTmZtHWMh",
        "outputId": "8880a011-2be4-4e90-f35c-c84bb16e68ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-13 21:21:35--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/4138/lustifyEndgame.OH7I.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22lustifySDXLNSFW_endgame.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250213/us-east-1/s3/aws4_request&X-Amz-Date=20250213T210415Z&X-Amz-SignedHeaders=host&X-Amz-Signature=352dd3c9ceed59f79887a0ae7d76acb986e555fa233f6c26ba6ad67e16c2a222\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 162.159.141.50, 172.66.1.46, 2a06:98c1:58::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|162.159.141.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6938043264 (6.5G)\n",
            "Saving to: ‘/content/Fooocus/models/checkpoints/lustify_sdxl_nsfw.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>]   6.46G   141MB/s    in 75s     \n",
            "\n",
            "2025-02-13 21:22:51 (87.8 MB/s) - ‘/content/Fooocus/models/checkpoints/lustify_sdxl_nsfw.safetensors’ saved [6938043264/6938043264]\n",
            "\n",
            "--2025-02-13 21:22:51--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/3326444/largeFlatBreastsSDXL.kI8b.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22large_flat_breasts_SDXL.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250213/us-east-1/s3/aws4_request&X-Amz-Date=20250213T203048Z&X-Amz-SignedHeaders=host&X-Amz-Signature=5a64f1299154fa5ea285b2a091c022a40e2e21c06d15e07e8a4b1d06bb7998bf\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 162.159.141.50, 172.66.1.46, 2a06:98c1:58::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|162.159.141.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228458668 (218M)\n",
            "Saving to: ‘/content/Fooocus/models/loras/large_flat_breasts_SDXL.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>] 217.88M  68.7MB/s    in 3.2s    \n",
            "\n",
            "2025-02-13 21:22:55 (68.7 MB/s) - ‘/content/Fooocus/models/loras/large_flat_breasts_SDXL.safetensors’ saved [228458668/228458668]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM2UKzVOHYBq",
        "outputId": "d229c58e-cd6c-4581-a896-6e8b29b1df20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Total VRAM 15095 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://a4b4f62995e3140d3d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Exception in thread Thread-2 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 181, in worker\n",
            "    import modules.default_pipeline as pipeline\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 270, in <module>\n",
            "    refresh_everything(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 263, in refresh_everything\n",
            "    final_expansion = FooocusExpansion()\n",
            "                      ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/extras/expansion.py\", line 39, in __init__\n",
            "    self.tokenizer = AutoTokenizer.from_pretrained(path_fooocus_expansion)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\", line 846, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 965, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 373, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: /content/Fooocus/models/prompt_expansion/fooocus_expansion does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/Fooocus/models/prompt_expansion/fooocus_expansion/tree/None' for available files.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}